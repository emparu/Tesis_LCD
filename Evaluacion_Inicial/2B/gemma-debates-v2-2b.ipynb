{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07d1d6d2",
   "metadata": {
    "id": "8cs1yid_Dhr1",
    "papermill": {
     "duration": 0.005619,
     "end_time": "2024-09-01T06:52:42.325627",
     "exception": false,
     "start_time": "2024-09-01T06:52:42.320008",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Instalar y desinstalar cosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a2b0ffa",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:52:42.335363Z",
     "iopub.status.busy": "2024-09-01T06:52:42.334863Z",
     "iopub.status.idle": "2024-09-01T06:53:01.319355Z",
     "shell.execute_reply": "2024-09-01T06:53:01.318488Z"
    },
    "papermill": {
     "duration": 18.992192,
     "end_time": "2024-09-01T06:53:01.321768",
     "exception": false,
     "start_time": "2024-09-01T06:52:42.329576",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: tensorflow 2.16.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uninstalling tensorflow-2.16.1:\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Successfully uninstalled tensorflow-2.16.1\r\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip uninstall tensorflow -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "83ea6af5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:53:01.332466Z",
     "iopub.status.busy": "2024-09-01T06:53:01.331713Z",
     "iopub.status.idle": "2024-09-01T06:53:48.713985Z",
     "shell.execute_reply": "2024-09-01T06:53:48.712947Z"
    },
    "id": "cbKk7lGzWiET",
    "papermill": {
     "duration": 47.390246,
     "end_time": "2024-09-01T06:53:48.716413",
     "exception": false,
     "start_time": "2024-09-01T06:53:01.326167",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q -U keras-nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c92eba83",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:53:48.728901Z",
     "iopub.status.busy": "2024-09-01T06:53:48.728033Z",
     "iopub.status.idle": "2024-09-01T06:53:54.955416Z",
     "shell.execute_reply": "2024-09-01T06:53:54.954429Z"
    },
    "id": "gIiY3YKJRsCL",
    "papermill": {
     "duration": 6.236043,
     "end_time": "2024-09-01T06:53:54.957692",
     "exception": false,
     "start_time": "2024-09-01T06:53:48.721649",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\r\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "!pip install -q keras==3.3.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50432e5a",
   "metadata": {
    "id": "kWgYYZflEjJs",
    "papermill": {
     "duration": 0.005145,
     "end_time": "2024-09-01T06:53:54.968302",
     "exception": false,
     "start_time": "2024-09-01T06:53:54.963157",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Set up Keras JAX backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ccbcbe2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:53:54.980248Z",
     "iopub.status.busy": "2024-09-01T06:53:54.979558Z",
     "iopub.status.idle": "2024-09-01T06:54:03.738190Z",
     "shell.execute_reply": "2024-09-01T06:54:03.737324Z"
    },
    "id": "WtH7QlcOXG6C",
    "outputId": "464946df-1bc9-49f6-c507-b4d41335357d",
    "papermill": {
     "duration": 8.766839,
     "end_time": "2024-09-01T06:54:03.740167",
     "exception": false,
     "start_time": "2024-09-01T06:53:54.973328",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before InitGoogle() is written to STDERR\n",
      "E0000 00:00:1725173639.651885      77 common_lib.cc:798] Could not set metric server port: INVALID_ARGUMENT: Could not find SliceBuilder port 8471 in any of the 0 ports provided in `tpu_process_addresses`=\"local\"\n",
      "=== Source Location Trace: ===\n",
      "learning/45eac/tfrc/runtime/common_lib.cc:479\n",
      "E0901 06:53:59.685490079      77 oauth2_credentials.cc:238]            oauth_fetch: UNKNOWN:C-ares status is not ARES_SUCCESS qtype=A name=metadata.google.internal. is_balancer=0: Domain name not found {created_time:\"2024-09-01T06:53:59.685472061+00:00\", grpc_status:2}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[TpuDevice(id=0, process_index=0, coords=(0,0,0), core_on_chip=0),\n",
       " TpuDevice(id=1, process_index=0, coords=(0,0,0), core_on_chip=1),\n",
       " TpuDevice(id=2, process_index=0, coords=(1,0,0), core_on_chip=0),\n",
       " TpuDevice(id=3, process_index=0, coords=(1,0,0), core_on_chip=1),\n",
       " TpuDevice(id=4, process_index=0, coords=(0,1,0), core_on_chip=0),\n",
       " TpuDevice(id=5, process_index=0, coords=(0,1,0), core_on_chip=1),\n",
       " TpuDevice(id=6, process_index=0, coords=(1,1,0), core_on_chip=0),\n",
       " TpuDevice(id=7, process_index=0, coords=(1,1,0), core_on_chip=1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import jax\n",
    "\n",
    "jax.devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec01f51d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:54:03.752315Z",
     "iopub.status.busy": "2024-09-01T06:54:03.751948Z",
     "iopub.status.idle": "2024-09-01T06:54:14.547773Z",
     "shell.execute_reply": "2024-09-01T06:54:14.546943Z"
    },
    "id": "lDiDLM3EXJem",
    "papermill": {
     "duration": 10.804248,
     "end_time": "2024-09-01T06:54:14.549974",
     "exception": false,
     "start_time": "2024-09-01T06:54:03.745726",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-01 06:54:11.746864: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-09-01 06:54:11.775484: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-09-01 06:54:11.775548: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# The Keras 3 distribution API is only implemented for the JAX backend for now\n",
    "os.environ[\"KERAS_BACKEND\"] = \"jax\"\n",
    "# Pre-allocate 90% of TPU memory to minimize memory fragmentation and allocation\n",
    "# overhead\n",
    "os.environ[\"XLA_PYTHON_CLIENT_MEM_FRACTION\"] = \"1.0\"\n",
    "\n",
    "import keras\n",
    "import keras_nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8613c2a7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:54:14.560860Z",
     "iopub.status.busy": "2024-09-01T06:54:14.560436Z",
     "iopub.status.idle": "2024-09-01T06:54:14.564027Z",
     "shell.execute_reply": "2024-09-01T06:54:14.563390Z"
    },
    "id": "alq-qBnec0Gb",
    "papermill": {
     "duration": 0.011142,
     "end_time": "2024-09-01T06:54:14.565754",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.554612",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "keras.config.set_floatx(\"bfloat16\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146390d4",
   "metadata": {
    "id": "LIKvQM2jYhCp",
    "papermill": {
     "duration": 0.004295,
     "end_time": "2024-09-01T06:54:14.574603",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.570308",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70990c86",
   "metadata": {
    "id": "yRs8exKlExW5",
    "papermill": {
     "duration": 0.004295,
     "end_time": "2024-09-01T06:54:14.583665",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.579370",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "To load the model with the weights and tensors distributed across TPUs, first create a new `DeviceMesh`. `DeviceMesh` represents a collection of hardware devices configured for distributed computation and was introduced in Keras 3 as part of the unified distribution API.\n",
    "\n",
    "The distribution API enables data and model parallelism, allowing for efficient scaling of deep learning models on multiple accelerators and hosts. It leverages the underlying framework (e.g. JAX) to distribute the program and tensors according to the sharding directives through a procedure called single program, multiple data (SPMD) expansion. Check out more details in the new [Keras 3 distribution API guide](https://keras.io/guides/distribution/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3184bea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:54:14.593836Z",
     "iopub.status.busy": "2024-09-01T06:54:14.593603Z",
     "iopub.status.idle": "2024-09-01T06:54:14.597365Z",
     "shell.execute_reply": "2024-09-01T06:54:14.596701Z"
    },
    "id": "HO_4KnoEXO_Y",
    "papermill": {
     "duration": 0.01057,
     "end_time": "2024-09-01T06:54:14.598881",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.588311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a device mesh with (1, 8) shape so that the weights are sharded across\n",
    "# all 8 TPUs.\n",
    "device_mesh = keras.distribution.DeviceMesh(\n",
    "    (2, 4),\n",
    "    [\"batch\", \"model\"],\n",
    "    devices=keras.distribution.list_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "647072a2",
   "metadata": {
    "id": "wKz4Z8iaFFow",
    "papermill": {
     "duration": 0.004696,
     "end_time": "2024-09-01T06:54:14.607951",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.603255",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`LayoutMap` from the distribution API specifies how the weights and tensors should be sharded or replicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "348cb225",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:54:14.618037Z",
     "iopub.status.busy": "2024-09-01T06:54:14.617807Z",
     "iopub.status.idle": "2024-09-01T06:54:14.621098Z",
     "shell.execute_reply": "2024-09-01T06:54:14.620460Z"
    },
    "id": "Duk_XeqdXTIG",
    "papermill": {
     "duration": 0.01056,
     "end_time": "2024-09-01T06:54:14.622799",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.612239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "layout_map = keras_nlp.models.GemmaBackbone.get_layout_map(device_mesh)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52841a94",
   "metadata": {
    "id": "KI58t0WvFS-4",
    "papermill": {
     "duration": 0.004227,
     "end_time": "2024-09-01T06:54:14.631738",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.627511",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "`ModelParallel` allows you to shard model weights or activation tensors across all devcies on the `DeviceMesh`. In this case, some of the Gemma 2 27B model weights are sharded across 8 TPU cores according to the `layout_map` defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d03c02a5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:54:14.642429Z",
     "iopub.status.busy": "2024-09-01T06:54:14.641925Z",
     "iopub.status.idle": "2024-09-01T06:54:14.645490Z",
     "shell.execute_reply": "2024-09-01T06:54:14.644756Z"
    },
    "id": "LSuY8ZGKXZ0q",
    "papermill": {
     "duration": 0.010561,
     "end_time": "2024-09-01T06:54:14.647011",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.636450",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_parallel = keras.distribution.ModelParallel(\n",
    "    device_mesh, layout_map, batch_dim_name=\"batch\")\n",
    "\n",
    "keras.distribution.set_distribution(model_parallel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1738144",
   "metadata": {
    "id": "zVvD9EeFFeRz",
    "papermill": {
     "duration": 0.004495,
     "end_time": "2024-09-01T06:54:14.655810",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.651315",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "Now load the Gemma 2 27B model in the distributed way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "397db042",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:54:14.666437Z",
     "iopub.status.busy": "2024-09-01T06:54:14.665779Z",
     "iopub.status.idle": "2024-09-01T06:55:22.398074Z",
     "shell.execute_reply": "2024-09-01T06:55:22.397319Z"
    },
    "id": "K4Gm8Ef8ZM9r",
    "outputId": "01db1b70-d9be-4e7b-f810-f8435e50ab2b",
    "papermill": {
     "duration": 67.739427,
     "end_time": "2024-09-01T06:55:22.399803",
     "exception": false,
     "start_time": "2024-09-01T06:54:14.660376",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "normalizer.cc(51) LOG(INFO) precompiled_charsmap is empty. use identity normalization.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"gemma_causal_lm_preprocessor\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mPreprocessor: \"gemma_causal_lm_preprocessor\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Tokenizer (type)                                   </span>┃<span style=\"font-weight: bold\">                                             Vocab # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaTokenizer</span>)                   │                                             <span style=\"color: #00af00; text-decoration-color: #00af00\">256,000</span> │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mTokenizer (type)                                  \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                            Vocab #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ gemma_tokenizer (\u001b[38;5;33mGemmaTokenizer\u001b[0m)                   │                                             \u001b[38;5;34m256,000\u001b[0m │\n",
       "└────────────────────────────────────────────────────┴─────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"gemma_causal_lm\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"gemma_causal_lm\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2304</span>)        │   <span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> │ padding_mask[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],        │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GemmaBackbone</span>)               │                           │                 │ token_ids[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256000</span>)      │     <span style=\"color: #00af00; text-decoration-color: #00af00\">589,824,000</span> │ gemma_backbone[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ReversibleEmbedding</span>)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ padding_mask (\u001b[38;5;33mInputLayer\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_ids (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ gemma_backbone                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2304\u001b[0m)        │   \u001b[38;5;34m2,614,341,888\u001b[0m │ padding_mask[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],        │\n",
       "│ (\u001b[38;5;33mGemmaBackbone\u001b[0m)               │                           │                 │ token_ids[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ token_embedding               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256000\u001b[0m)      │     \u001b[38;5;34m589,824,000\u001b[0m │ gemma_backbone[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "│ (\u001b[38;5;33mReversibleEmbedding\u001b[0m)         │                           │                 │                            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (4.87 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (4.87 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,614,341,888</span> (4.87 GB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,614,341,888\u001b[0m (4.87 GB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "gemma2_lm = keras_nlp.models.GemmaCausalLM.from_preset(\"gemma2_instruct_2b_en\")\n",
    "gemma2_lm.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "73975bd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:55:22.412189Z",
     "iopub.status.busy": "2024-09-01T06:55:22.411929Z",
     "iopub.status.idle": "2024-09-01T06:55:22.455656Z",
     "shell.execute_reply": "2024-09-01T06:55:22.454865Z"
    },
    "papermill": {
     "duration": 0.0523,
     "end_time": "2024-09-01T06:55:22.457573",
     "exception": false,
     "start_time": "2024-09-01T06:55:22.405273",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = keras_nlp.samplers.RandomSampler()\n",
    "gemma2_lm.compile(sampler=sampler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "53681000",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:55:22.470352Z",
     "iopub.status.busy": "2024-09-01T06:55:22.470044Z",
     "iopub.status.idle": "2024-09-01T06:55:22.661259Z",
     "shell.execute_reply": "2024-09-01T06:55:22.660335Z"
    },
    "papermill": {
     "duration": 0.20006,
     "end_time": "2024-09-01T06:55:22.663458",
     "exception": false,
     "start_time": "2024-09-01T06:55:22.463398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "random.seed(42)\n",
    "\n",
    "# Function to create a prompt with randomly ordered answers\n",
    "def create_prompt_with_random_answers(article, question, correct_answer, wrong_answer):\n",
    "    # Randomly decide whether to place the correct answer as 1 or 2\n",
    "    if random.choice([True, False]):\n",
    "        answer_1, answer_2 = correct_answer, wrong_answer\n",
    "        correct_answer_position = 1\n",
    "    else:\n",
    "        answer_1, answer_2 = wrong_answer, correct_answer\n",
    "        correct_answer_position = 2\n",
    "\n",
    "    # Create the prompt string\n",
    "    prompt = f\"\"\"<bos><start_of_turn>user\n",
    "This is a passage:\n",
    "---\n",
    "{article}\n",
    "---\n",
    "Please analyze the passage carefully and select the correct answer for the following question. Before choosing your answer, explain your reasoning step by step:\n",
    "---\n",
    "<question>{question}<\\question>\n",
    "---\n",
    "Answer options:\n",
    "Option A1A. <answer>{answer_1}<\\answer>\n",
    "Option A2A. <answer>{answer_2}<\\answer>\n",
    "---\n",
    "Write your reasoning step by step and THEN write your final answer.\n",
    "Indicate your response as \"The answer is A1A\" if you chose option 1 or \"The answer is A2A\" if you chose option 2 based on the option you believe is correct.\n",
    "\n",
    "Make sure to indicate your response as \"The answer is A1A\" or \"The answer is A2A\" in the correct format, otherwise it will be unreadable.<end_of_turn>\n",
    "<start_of_turn>model\"\"\"\n",
    "    \n",
    "    return prompt, correct_answer_position\n",
    "\n",
    "# Function to process a single CSV file and generate the prompts and correct answer positions\n",
    "def process_dataset(csv_file):\n",
    "    # Read the CSV file\n",
    "    df = pd.read_csv(csv_file)\n",
    "\n",
    "    # Lists to store the prompts and correct answer positions\n",
    "    prompts = []\n",
    "    correct_answer_positions = []\n",
    "\n",
    "    # Iterate through the dataset to create prompts and track correct answer positions\n",
    "    for _, row in df.iterrows():\n",
    "        article = row['article']\n",
    "        question = row['question']\n",
    "        correct_answer = row['correct_answer']\n",
    "        wrong_answer = row['wrong_answer']\n",
    "\n",
    "        prompt, correct_answer_position = create_prompt_with_random_answers(article, question, correct_answer, wrong_answer)\n",
    "        prompts.append(prompt)\n",
    "        correct_answer_positions.append(correct_answer_position)\n",
    "\n",
    "    return prompts, correct_answer_positions\n",
    "\n",
    "# Process the easy and hard development datasets separately\n",
    "prompts_easy, correct_answers_easy = process_dataset('/kaggle/input/quality-preprocessed/selected_data_easy_dev.csv')\n",
    "prompts_hard, correct_answers_hard = process_dataset('/kaggle/input/quality-preprocessed/selected_data_hard_dev.csv')\n",
    "\n",
    "# Example of how to print the results\n",
    "# for i, prompt in enumerate(prompts_easy[:3]):  # Print first 3 prompts as an example for easy\n",
    "#     print(f\"Easy Prompt {i+1}:\\n{prompt}\\nCorrect answer position: {correct_answers_easy[i]}\\n\")\n",
    "\n",
    "# for i, prompt in enumerate(prompts_hard[:3]):  # Print first 3 prompts as an example for hard\n",
    "#     print(f\"Hard Prompt {i+1}:\\n{prompt}\\nCorrect answer position: {correct_answers_hard[i]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d521a390",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:55:22.675812Z",
     "iopub.status.busy": "2024-09-01T06:55:22.675524Z",
     "iopub.status.idle": "2024-09-01T06:55:22.680119Z",
     "shell.execute_reply": "2024-09-01T06:55:22.679320Z"
    },
    "papermill": {
     "duration": 0.012791,
     "end_time": "2024-09-01T06:55:22.681713",
     "exception": false,
     "start_time": "2024-09-01T06:55:22.668922",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def extract_answer_number(generated_text):\n",
    "    # Find the part of the text after \"<start_of_turn>model\"\n",
    "    model_response = re.split(r'<start_of_turn>model', generated_text, maxsplit=1)[-1]\n",
    "\n",
    "    match = re.search(r'A(\\d)A', model_response[::-1])\n",
    "    #print(match)\n",
    "    if match:\n",
    "        return int(match.group(1))\n",
    "    else:\n",
    "        return None  # Return None if no answer is found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe6c159",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:55:22.693601Z",
     "iopub.status.busy": "2024-09-01T06:55:22.693370Z",
     "iopub.status.idle": "2024-09-01T06:56:01.691731Z",
     "shell.execute_reply": "2024-09-01T06:56:01.690683Z"
    },
    "papermill": {
     "duration": 39.012363,
     "end_time": "2024-09-01T06:56:01.699346",
     "exception": false,
     "start_time": "2024-09-01T06:55:22.686983",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted answer number: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Example usage\n",
    "generated_output = gemma2_lm.generate(prompts_easy[0])\n",
    "#print(generated_output)\n",
    "answer_number = extract_answer_number(generated_output)\n",
    "print(f\"Extracted answer number: {answer_number}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7dcc6e52",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:56:01.713475Z",
     "iopub.status.busy": "2024-09-01T06:56:01.712782Z",
     "iopub.status.idle": "2024-09-01T06:56:51.260839Z",
     "shell.execute_reply": "2024-09-01T06:56:51.259939Z"
    },
    "papermill": {
     "duration": 49.562261,
     "end_time": "2024-09-01T06:56:51.267776",
     "exception": false,
     "start_time": "2024-09-01T06:56:01.705515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Function to evaluate the model's performance on a given set of prompts\n",
    "def evaluate_model(prompts, correct_answers, dataset_name):\n",
    "    model_outputs = []\n",
    "    extracted_answers = []\n",
    "\n",
    "    # Generate outputs in parallel (in batches of 16)\n",
    "    for i in range(0, len(prompts), 16):\n",
    "        batch_prompts = prompts[i:i+16]\n",
    "        generated_outputs = gemma2_lm.generate(batch_prompts)\n",
    "        \n",
    "        for output in generated_outputs:\n",
    "            model_outputs.append(output)\n",
    "            extracted_answer = extract_answer_number(output)\n",
    "            extracted_answers.append(extracted_answer)\n",
    "            print(extracted_answer)\n",
    "\n",
    "    # Save results to CSV\n",
    "    results_df = pd.DataFrame({\n",
    "        'prompt': prompts,\n",
    "        'model_output': model_outputs,\n",
    "        'correct_answer': correct_answers,\n",
    "        'extracted_answer': extracted_answers\n",
    "    })\n",
    "    results_df.to_csv(f'{dataset_name}_evaluation_results.csv', index=False)\n",
    "\n",
    "# Test with the first 5 rows of the easy dataset\n",
    "evaluate_model(prompts_easy[:5], correct_answers_easy[:5], \"easy_dev_sample\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "adf0d171",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-09-01T06:56:51.280723Z",
     "iopub.status.busy": "2024-09-01T06:56:51.280414Z",
     "iopub.status.idle": "2024-09-01T07:42:56.295671Z",
     "shell.execute_reply": "2024-09-01T07:42:56.294685Z"
    },
    "papermill": {
     "duration": 2765.024217,
     "end_time": "2024-09-01T07:42:56.297589",
     "exception": false,
     "start_time": "2024-09-01T06:56:51.273372",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "None\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "None\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "None\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "2\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "2\n",
      "1\n",
      "1\n",
      "1\n",
      "1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the full datasets\n",
    "evaluate_model(prompts_easy, correct_answers_easy, \"easy_dev_full\")\n",
    "evaluate_model(prompts_hard, correct_answers_hard, \"hard_dev_full\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "machine_shape": "hm",
   "provenance": []
  },
  "kaggle": {
   "accelerator": "tpu1vmV38",
   "dataSources": [
    {
     "datasetId": 5624423,
     "sourceId": 9291447,
     "sourceType": "datasetVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 57806,
     "sourceId": 69289,
     "sourceType": "modelInstanceVersion"
    },
    {
     "modelId": 78150,
     "modelInstanceId": 57466,
     "sourceId": 82368,
     "sourceType": "modelInstanceVersion"
    },
    {
     "isSourceIdPinned": true,
     "modelId": 78150,
     "modelInstanceId": 72246,
     "sourceId": 85986,
     "sourceType": "modelInstanceVersion"
    }
   ],
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3020.948494,
   "end_time": "2024-09-01T07:43:01.753897",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-09-01T06:52:40.805403",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
